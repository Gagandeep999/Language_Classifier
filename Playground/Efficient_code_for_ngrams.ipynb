{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "defaultSmoothing = 10e-10\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']\n",
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=1000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]\n",
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[ ]')\n",
    "_df0.head()\n",
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if letter.isalpha() or pattern.match(letter):\n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDict.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UNIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=(%sSize+1))\" %(language, language))\n",
    "    exec('self.{L}Model = np.add(self.{L}Model, defaultSmoothing)'.format(L=language))\n",
    "\n",
    "start_time = datetime.now()\n",
    "delta = 0\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-1):\n",
    "            first = tweet[i]\n",
    "            exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary \n",
    "            exec('%sModel[index] += 1'%(language)) #increment that index in the language model\n",
    "for language in languages:\n",
    "#     exec('%sModelTemp = %sModel[:]'%(language, language))\n",
    "    exec('%sModelTemp = np.add(%sModelTemp, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModelTemp = np.divide(%sModelTemp, %sModel.sum(axis=0))'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModelTemp = np.log10(%sModelTemp)'%(language, language))\n",
    "#     exec('%sModel[:] = %sModelTemp'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "    exec('{L}Model = np.add({L}Model, defaultSmoothing)'.format(L=language))\n",
    "    \n",
    "start_time = datetime.now()\n",
    "delta = 0\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-2):\n",
    "            first = tweet[i]\n",
    "            second = tweet[i+1]\n",
    "            exec('firstIndex = %sAlphabets[first]'%(language))\n",
    "            exec('secondIndex = %sAlphabets[second]'%(language))\n",
    "            exec('%sModel[firstIndex][secondIndex] += 1'%(language))\n",
    "# here the Model.sum(axis=1) instead of axis=0 for uni/trigrams. Helps to avoid haveing a loop for every row of 2D array.\n",
    "for language in languages:\n",
    "    exec('%sModel = np.add(%sModel, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModel = %sModel/%sModel.sum(axis=1)'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE MODEL FOR 1D OR 2D\n",
    "\n",
    "```python\n",
    "for language in languages:\n",
    "    exec('np.savetxt(\\'{L}ModelBigram.model\\', {L}Model, delimiter=\\',\\', fmt=\\'%1.2e\\')'.format(L=language))\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec('np.savetxt(\\'{L}ModelBigram.model\\', {L}Model, delimiter=\\',\\', fmt=\\'%1.2e\\')'.format(L=language))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRIGRAMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec('{lang}Model=np.zeros(shape=(({lang}Size+1),({lang}Size+1),({lang}Size+1)))'.format(lang=language))#, language, language, language))\n",
    "    exec('{L}Model = np.add({L}Model, defaultSmoothing)'.format(L=language))\n",
    "    \n",
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-2):\n",
    "            first = tweet[i]\n",
    "            second = tweet[i+1]\n",
    "            third = tweet[i+2]\n",
    "            exec('firstIndex = %sAlphabets[first]'%(language))\n",
    "            exec('secondIndex = %sAlphabets[second]'%(language))\n",
    "            exec('thirdIndex = %sAlphabets[third]'%(language))\n",
    "            exec('%sModel[firstIndex][secondIndex][thirdIndex] += 1'%(language))\n",
    "for language in languages:\n",
    "    exec('for x in range({lang}Model.shape[0]):\\n\\\n",
    "    for y in range({lang}Model.shape[1]):\\n\\\n",
    "        {lang}ModelTemp = {lang}Model[x,y,:]\\n\\\n",
    "        {lang}ModelTemp = np.add({lang}ModelTemp, delta)\\n\\\n",
    "        {lang}ModelTemp = np.divide({lang}ModelTemp, {lang}ModelTemp.sum(axis=0))\\n\\\n",
    "        {lang}ModelTemp = np.log10({lang}ModelTemp)\\n\\\n",
    "        {lang}Model[x,y,:] = {lang}ModelTemp\\n'.format(lang=language))\n",
    "\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SAVE MODEL FOR 3D\n",
    "\n",
    "```python\n",
    "for language in languages:\n",
    "    exec('outfile = open(\\'{L}ModelTrigram.model\\', \\'w\\')\\n\\\n",
    "    print(\\'# Shape \\', {L}Model.shape, file=outfile)\\n\\\n",
    "    outfile.flush()\\n\\\n",
    "    print(\\'# To load model - new_data = np.loadtxt(filename)\\', file=outfile)\\n\\\n",
    "    outfile.flush()\\n\\\n",
    "    print(\\'# Reshape the data - new_data = new_data.reshape((shape))\\', file=outfile)\\n\\\n",
    "    outfile.flush()\\n\\\n",
    "    for data_slice in {L}Model:\\n\\\n",
    "        np.savetxt(outfile, data_slice, delimiter=\\',\\', fmt=\\'%1.2e\\')'.format(L=language))\n",
    "``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
