{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=15000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[ ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if letter.isalpha() or pattern.match(letter):\n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enSize)\n",
    "print(enAlphabets)\n",
    "print(esSize)\n",
    "print(esAlphabets)\n",
    "print(euSize)\n",
    "print(euAlphabets)\n",
    "print(caSize)\n",
    "print(caAlphabets)\n",
    "print(ptSize)\n",
    "print(ptAlphabets)\n",
    "print(glSize)\n",
    "print(glAlphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "#     exec(\"%sCount=0\" %(language))\n",
    "#     exec(\"%sEachWordCount=dict.fromkeys(%sAlphabets, 0)\" %(language, language)) #needed for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = dict.fromkeys(a, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# delta = 0.5\n",
    "# for language, tweets in trainDict.items():\n",
    "#     for tweet in tweets:\n",
    "#         for i in range(len(tweet)-1):\n",
    "#             first = tweet[i]\n",
    "#             exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary\n",
    "#             exec('%sModel[index] += 1'%(language)) #np.add.at(esModel, [index], 1) #increment that index in the language model\n",
    "# for language in languages:\n",
    "#     exec('%sModel = %sModel/%sModel.sum()'%(language, language, language)) #divide all the values by the sum of the row\n",
    "#     exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "# print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-2):\n",
    "            first = tweet[i]\n",
    "            second = tweet[i+1]\n",
    "            exec('firstIndex = %sAlphabets[first]'%(language))\n",
    "            exec('secondIndex = %sAlphabets[second]'%(language))\n",
    "            exec('%sModel[firstIndex][secondIndex] += 1'%(language))\n",
    "for language in languages:\n",
    "    exec('%sModel = np.add(%sModel, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModel = %sModel/%sModel.sum(axis=1)'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glSum = glModel.sum()\n",
    "# ptSum = ptModel.sum()\n",
    "# caSum = caModel.sum()\n",
    "# euSum = euModel.sum()\n",
    "# esSum = esModel.sum()\n",
    "# enSum = enModel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('enSum', enSum ,'\\nesSum', esSum ,'\\neuSum', euSum ,'\\ncaSum', caSum ,'\\nptSum', ptSum, '\\nglSum', glSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/test-tweets-given.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=100)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]\n",
    "_df0 = df[['TweetID', 'Language', 'Tweet']].copy()\n",
    "# pattern = re.compile('[a-z ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = {}\n",
    "for index, row in _df0.iterrows():\n",
    "    for language in languages:\n",
    "        exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "    tweetID = row['TweetID']\n",
    "    langTweet = row['Language']\n",
    "    tweet = row['Tweet']\n",
    "    \n",
    "    for i in range(len(tweet)-2):\n",
    "        first = tweet[i]\n",
    "        second = tweet[i+1]\n",
    "        for lang in languages:\n",
    "            exec('if ((first not in {0}Alphabets.keys()) and (second not in {1}Alphabets.keys())):\\n\\\n",
    "    prob = {2}Model[-1][-1]\\n\\\n",
    "elif (second not in {3}Alphabets.keys()):\\n\\\n",
    "    index = {4}Alphabets[first]\\n\\\n",
    "    prob = {5}Model[index][-1]\\n\\\n",
    "elif (first not in {6}Alphabets.keys()):\\n\\\n",
    "    index = {7}Alphabets[second]\\n\\\n",
    "    prob = {8}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {9}Alphabets[first]\\n\\\n",
    "    secondIndex = {10}Alphabets[second]\\n\\\n",
    "    prob = {11}Model[firstIndex][secondIndex]\\n\\\n",
    "{12}Prob = prob + {13}Prob\\n'.format(lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang))\n",
    "    for langu in languages:\n",
    "        exec(\"probability['%s'] = %sProb\"%(langu, langu))\n",
    "#     probability[lang] = enProb\n",
    "#     print(probability)\n",
    "#     print('tweet: ', tweet,'\\nenProb:', enProb, '\\neuProb:', euProb, '\\nesProb:', esProb, '\\ncaProb:', caProb\n",
    "#     ,'\\nptProb:', ptProb, '\\nglProb:', glProb)\n",
    "    result = max(probability, key=probability.get)\n",
    "    print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', langTweet, 'correct' if (langTweet==result) else 'wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# probability = {}\n",
    "# for index, row in _df0.iterrows():\n",
    "#     for language in languages:\n",
    "#         exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "#     tweetID = row['TweetID']\n",
    "#     lang = row['Language']\n",
    "#     tweet = row['Tweet']\n",
    "#     for i in range(len(tweet)-2):\n",
    "#         first = tweet[i]\n",
    "#         second = tweet[i+1]\n",
    "#         for lang in languages:\n",
    "#             if ((first not in enDict.keys()) and (second not in enDict.keys())):\n",
    "#                 #take the last entry of the model\n",
    "#                 prob = enModel[-1][-1]\n",
    "#             elif (second not in enDict.keys()):\n",
    "#                 #take the coreesponding row but last column\n",
    "#                 index = enDict[first]\n",
    "#                 prob = enModel[index][-1]\n",
    "#             elif (first not in enDict.keys()): \n",
    "#                 #take the last row and the corresponding column\n",
    "#                 index = enDict[second]\n",
    "#                 prob = enModel[-1][index]\n",
    "#             else:\n",
    "#                 #both are in the matrix\n",
    "#                 firstIndex = enDict[first]\n",
    "#                 secondIndex = enDict[second]\n",
    "#                 prob = enModel[firstIndex][secondIndex]\n",
    "#             enProb = prob + enProb\n",
    "#     probability['en'] = enProb\n",
    "    \n",
    "#     result = max(probability, key=probability.get)\n",
    "#     print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', lang, 'correct' if (lang==result) else 'wrong')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
