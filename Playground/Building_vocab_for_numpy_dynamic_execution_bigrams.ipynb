{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=18000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[ ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if letter.isalpha() or pattern.match(letter):\n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enSize)\n",
    "print(enAlphabets)\n",
    "print(esSize)\n",
    "print(esAlphabets)\n",
    "print(euSize)\n",
    "print(euAlphabets)\n",
    "print(caSize)\n",
    "print(caAlphabets)\n",
    "print(ptSize)\n",
    "print(ptAlphabets)\n",
    "print(glSize)\n",
    "print(glAlphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "#     exec(\"%sModelFinal=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "#     exec(\"%sCount=0\" %(language))\n",
    "#     exec(\"%sEachWordCount=dict.fromkeys(%sAlphabets, 0)\" %(language, language)) #needed for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = dict.fromkeys(a, 0)\n",
    "# print(trainDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# delta = 0.5\n",
    "# for language, tweets in trainDict.items():\n",
    "#     for tweet in tweets:\n",
    "#         for i in range(len(tweet)-1):\n",
    "#             first = tweet[i]\n",
    "#             exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary\n",
    "#             exec('%sModel[index] += 1'%(language)) #np.add.at(esModel, [index], 1) #increment that index in the language model\n",
    "# for language in languages:\n",
    "#     exec('%sModel = %sModel/%sModel.sum()'%(language, language, language)) #divide all the values by the sum of the row\n",
    "#     exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "# print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-2):\n",
    "            first = tweet[i]\n",
    "            second = tweet[i+1]\n",
    "            exec('firstIndex = %sAlphabets[first]'%(language))\n",
    "            exec('secondIndex = %sAlphabets[second]'%(language))\n",
    "            exec('%sModel[firstIndex][secondIndex] += 1'%(language))\n",
    "for language in languages:\n",
    "    exec('%sModel = np.add(%sModel, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModel = %sModel/%sModel.sum(axis=1)'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec('print(\\'%s\\', %sModel)'%(language, language))\n",
    "#     exec('print(\\'%s\\', %sModelFinal)'%(language, language))\n",
    "\n",
    "# print('EN',enModel, enModel.shape)\n",
    "# print('EN',enModel, enModel.shape)\n",
    "# print('ES',esModel, esModel.shape)\n",
    "# print('ES',esModel, esModel.shape)\n",
    "# print('EU',euModel, euModel.shape)\n",
    "# print('EU',euModel, euModel.shape)\n",
    "# print('CA',caModel, caModel.shape)\n",
    "# print('PT',ptModel, ptModel.shape)\n",
    "# print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glSum = glModel.sum()\n",
    "# ptSum = ptModel.sum()\n",
    "# caSum = caModel.sum()\n",
    "# euSum = euModel.sum()\n",
    "# esSum = esModel.sum()\n",
    "# enSum = enModel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('enSum', enSum ,'\\nesSum', esSum ,'\\neuSum', euSum ,'\\ncaSum', caSum ,'\\nptSum', ptSum, '\\nglSum', glSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enModel)\n",
    "row = enModel[0:1]\n",
    "# print('row: ', row)\n",
    "# y = np.zeros(shape=((row.shape)))\n",
    "colum = enModel[0][0]\n",
    "# print('column', colum)\n",
    "\n",
    "x = row\n",
    "y = np.full((row.shape), row[0][0])\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "xAxis = enAlphabets.keys()\n",
    "# print(xAxis)\n",
    "\n",
    "# print('x:\\n',x)\n",
    "# print('y:\\n ',y)\n",
    "area = (10 * np.random.rand(x.shape[0]))**2\n",
    "colors = np.random.rand(x.shape[0])\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "colors = np.random.rand(N)\n",
    "area = (30 * np.random.rand(N))**2  # 0 to 15 point radii\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no axes\n",
    "fig.suptitle('First Trial')  # Add a title so we know which it is\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.3)\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/test-tweets-given.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=100)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]\n",
    "_df0 = df[['TweetID', 'Language', 'Tweet']].copy()\n",
    "# pattern = re.compile('[a-z ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = {}\n",
    "for index, row in _df0.iterrows():\n",
    "    for language in languages:\n",
    "        exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "    tweetID = row['TweetID']\n",
    "    langTweet = row['Language']\n",
    "    tweet = row['Tweet']\n",
    "    \n",
    "    for i in range(len(tweet)-2):\n",
    "        first = tweet[i]\n",
    "        second = tweet[i+1]\n",
    "        for lang in languages:\n",
    "            exec('if ((first not in {0}Alphabets.keys()) and (second not in {1}Alphabets.keys())):\\n\\\n",
    "    prob = {2}Model[-1][-1]\\n\\\n",
    "elif (second not in {3}Alphabets.keys()):\\n\\\n",
    "    index = {4}Alphabets[first]\\n\\\n",
    "    prob = {5}Model[index][-1]\\n\\\n",
    "elif (first not in {6}Alphabets.keys()):\\n\\\n",
    "    index = {7}Alphabets[second]\\n\\\n",
    "    prob = {8}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {9}Alphabets[first]\\n\\\n",
    "    secondIndex = {10}Alphabets[second]\\n\\\n",
    "    prob = {11}Model[firstIndex][secondIndex]\\n\\\n",
    "{12}Prob = prob + {13}Prob\\n'.format(lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang))\n",
    "    for langu in languages:\n",
    "        exec(\"probability['%s'] = %sProb\"%(langu, langu))\n",
    "#     probability[lang] = enProb\n",
    "#     print(probability)\n",
    "#     print('tweet: ', tweet,'\\nenProb:', enProb, '\\neuProb:', euProb, '\\nesProb:', esProb, '\\ncaProb:', caProb\n",
    "#     ,'\\nptProb:', ptProb, '\\nglProb:', glProb)\n",
    "    result = max(probability, key=probability.get)\n",
    "    print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', langTweet, 'correct' if (langTweet==result) else 'wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = {}\n",
    "for index, row in _df0.iterrows():\n",
    "    for language in languages:\n",
    "        exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "    tweetID = row['TweetID']\n",
    "    langTweet = row['Language']\n",
    "    tweet = row['Tweet']\n",
    "    \n",
    "    for i in range(len(tweet)-2):\n",
    "        first = tweet[i]\n",
    "        second = tweet[i+1]\n",
    "        for language in languages:\n",
    "            exec('if ((first not in {lang}Alphabets.keys()) and (second not in {lang}Alphabets.keys())):\\n\\\n",
    "    prob = {lang}Model[-1][-1]\\n\\\n",
    "elif (second not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[first]\\n\\\n",
    "    prob = {lang}Model[index][-1]\\n\\\n",
    "elif (first not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {lang}Alphabets[first]\\n\\\n",
    "    secondIndex = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[firstIndex][secondIndex]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang=language))\n",
    "    for langu in languages:\n",
    "        exec(\"probability['%s'] = %sProb\"%(langu, langu))\n",
    "    result = max(probability, key=probability.get)\n",
    "    print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', langTweet, 'correct' if (langTweet==result) else 'wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'es'\n",
    "str = 'if ((first not in {lang}Alphabets.keys()) and (second not in {lang}Alphabets.keys())):\\n\\\n",
    "    prob = {lang}Model[-1][-1]\\n\\\n",
    "elif (second not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[first]\\n\\\n",
    "    prob = {lang}Model[index][-1]\\n\\\n",
    "elif (first not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {lang}Alphabets[first]\\n\\\n",
    "    secondIndex = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[firstIndex][secondIndex]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang=language)#, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang)\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
