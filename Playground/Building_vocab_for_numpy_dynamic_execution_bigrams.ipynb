{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numpy:  1.17.2\n",
      "pandas:  1.0.3\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "from decimal import Decimal\n",
    "import matplotlib.pyplot as plt\n",
    "import pylab\n",
    "\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 17: expected 4 fields, saw 5\\nSkipping line 33: expected 4 fields, saw 5\\nSkipping line 44: expected 4 fields, saw 5\\nSkipping line 58: expected 4 fields, saw 5\\nSkipping line 61: expected 4 fields, saw 5\\nSkipping line 64: expected 4 fields, saw 5\\nSkipping line 74: expected 4 fields, saw 5\\nSkipping line 91: expected 4 fields, saw 5\\nSkipping line 99: expected 4 fields, saw 5\\nSkipping line 140: expected 4 fields, saw 5\\nSkipping line 145: expected 4 fields, saw 5\\nSkipping line 148: expected 4 fields, saw 5\\nSkipping line 152: expected 4 fields, saw 5\\nSkipping line 171: expected 4 fields, saw 5\\nSkipping line 178: expected 4 fields, saw 5\\nSkipping line 197: expected 4 fields, saw 5\\nSkipping line 201: expected 4 fields, saw 5\\nSkipping line 203: expected 4 fields, saw 5\\nSkipping line 213: expected 4 fields, saw 5\\nSkipping line 216: expected 4 fields, saw 5\\n'\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=18000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Language</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>es</td>\n",
       "      <td>Pedazo de tarta k me e kurrao!!!! Ske k buena ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>es</td>\n",
       "      <td>No hace falta que te digan que vas a morir par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>es</td>\n",
       "      <td>Empieza mi findeeeee :))))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>es</td>\n",
       "      <td>Pr칩xima parada: Carnaval del Toro de Ciudad Ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>es</td>\n",
       "      <td>Graniza y tal.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Language                                              Tweet\n",
       "0       es  Pedazo de tarta k me e kurrao!!!! Ske k buena ...\n",
       "1       es  No hace falta que te digan que vas a morir par...\n",
       "2       es                         Empieza mi findeeeee :))))\n",
       "3       es  Pr칩xima parada: Carnaval del Toro de Ciudad Ro...\n",
       "4       es                                     Graniza y tal."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[a-zA-Z]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading time (hh:mm:ss.ms) 0:00:31.511661\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if pattern.match(letter): #letter.isalpha() or \n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "        else:\n",
    "            sentence = sentence + ' '\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "52\n",
      "{'I': 0, 'M': 1, 'C': 2, 'O': 3, 'N': 4, 'F': 5, 'U': 6, 'S': 7, 'E': 8, 'D': 9, 'W': 10, 'H': 11, 'A': 12, 'T': 13, 'R': 14, 'L': 15, 'J': 16, 'j': 17, 'u': 18, 's': 19, 't': 20, 'i': 21, 'n': 22, 'b': 23, 'e': 24, 'r': 25, 'a': 26, 'f': 27, 'o': 28, 'd': 29, 'y': 30, 'p': 31, 'h': 32, 'P': 33, 'm': 34, 'l': 35, 'c': 36, 'Q': 37, 'Z': 38, 'B': 39, 'z': 40, 'v': 41, 'g': 42, 'k': 43, 'w': 44, 'Y': 45, 'x': 46, 'K': 47, 'V': 48, 'X': 49, 'q': 50, 'G': 51}\n",
      "52\n",
      "{'P': 0, 'e': 1, 'd': 2, 'a': 3, 'z': 4, 'o': 5, 't': 6, 'r': 7, 'k': 8, 'm': 9, 'u': 10, 'S': 11, 'b': 12, 'n': 13, 's': 14, 'y': 15, 'l': 16, 'h': 17, 'g': 18, 'J': 19, 'j': 20, 'p': 21, 'c': 22, 'O': 23, 'L': 24, 'f': 25, 'D': 26, 'X': 27, 'N': 28, 'q': 29, 'i': 30, 'v': 31, 'E': 32, 'x': 33, 'C': 34, 'T': 35, 'R': 36, 'G': 37, 'M': 38, 'A': 39, 'I': 40, 'V': 41, 'H': 42, 'F': 43, 'K': 44, 'W': 45, 'Q': 46, 'Z': 47, 'B': 48, 'Y': 49, 'U': 50, 'w': 51}\n",
      "52\n",
      "{'A': 0, 'n': 1, 'd': 2, 'e': 3, 'r': 4, 'R': 5, 'u': 6, 'i': 7, 'z': 8, 'b': 9, 'a': 10, 'k': 11, 't': 12, 'o': 13, 'l': 14, 'p': 15, 'x': 16, 'm': 17, 'h': 18, 'P': 19, 'j': 20, 'I': 21, 's': 22, 'g': 23, 'E': 24, 'y': 25, 'v': 26, 'O': 27, 'J': 28, 'f': 29, 'H': 30, 'M': 31, 'B': 32, 'D': 33, 'T': 34, 'Z': 35, 'G': 36, 'c': 37, 'U': 38, 'S': 39, 'L': 40, 'N': 41, 'X': 42, 'W': 43, 'K': 44, 'q': 45, 'Y': 46, 'w': 47, 'Q': 48, 'F': 49, 'C': 50, 'V': 51}\n",
      "52\n",
      "{'J': 0, 'o': 1, 's': 2, 'e': 3, 'p': 4, 'C': 5, 'l': 6, 'a': 7, 'q': 8, 'i': 9, 'r': 10, 'm': 11, 'u': 12, 'n': 13, 'b': 14, 't': 15, 'x': 16, 'f': 17, 'v': 18, 'g': 19, 'c': 20, 'A': 21, 'd': 22, 'M': 23, 'S': 24, 'h': 25, 'L': 26, 'O': 27, 'E': 28, 'k': 29, 'y': 30, 'Q': 31, 'K': 32, 'V': 33, 'N': 34, 'T': 35, 'B': 36, 'D': 37, 'P': 38, 'H': 39, 'z': 40, 'G': 41, 'j': 42, 'I': 43, 'w': 44, 'U': 45, 'F': 46, 'W': 47, 'R': 48, 'Z': 49, 'Y': 50, 'X': 51}\n",
      "52\n",
      "{'a': 0, 'n': 1, 't': 2, 'o': 3, 'l': 4, 's': 5, 'd': 6, 'F': 7, 'r': 8, 'X': 9, 'e': 10, 'D': 11, 'R': 12, 'u': 13, 'i': 14, 'k': 15, 'v': 16, 'H': 17, 'm': 18, 'M': 19, 'h': 20, 'p': 21, 'q': 22, 'g': 23, 'c': 24, 'A': 25, 'b': 26, 'f': 27, 'U': 28, 'y': 29, 'Z': 30, 'O': 31, 'w': 32, 'x': 33, 'T': 34, 'B': 35, 'z': 36, 'j': 37, 'C': 38, 'Y': 39, 'L': 40, 'S': 41, 'I': 42, 'G': 43, 'P': 44, 'E': 45, 'Q': 46, 'J': 47, 'V': 48, 'N': 49, 'W': 50, 'K': 51}\n",
      "52\n",
      "{'M': 0, 'o': 1, 'i': 2, 't': 3, 'a': 4, 's': 5, 'g': 6, 'r': 7, 'c': 8, 'F': 9, 'e': 10, 'l': 11, 'x': 12, 'C': 13, 'L': 14, 'n': 15, 'd': 16, 'u': 17, 'j': 18, 'b': 19, 'z': 20, 'f': 21, 'v': 22, 'p': 23, 'q': 24, 'm': 25, 'S': 26, 'J': 27, 'A': 28, 'P': 29, 'R': 30, 'B': 31, 'X': 32, 'D': 33, 'N': 34, 'O': 35, 'h': 36, 'T': 37, 'Y': 38, 'E': 39, 'V': 40, 'I': 41, 'U': 42, 'H': 43, 'y': 44, 'G': 45, 'Q': 46, 'W': 47, 'w': 48, 'Z': 49, 'k': 50, 'K': 51}\n"
     ]
    }
   ],
   "source": [
    "print(enSize)\n",
    "print(enAlphabets)\n",
    "print(esSize)\n",
    "print(esAlphabets)\n",
    "print(euSize)\n",
    "print(euAlphabets)\n",
    "print(caSize)\n",
    "print(caAlphabets)\n",
    "print(ptSize)\n",
    "print(ptAlphabets)\n",
    "print(glSize)\n",
    "print(glAlphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "#     exec(\"%sModelFinal=np.zeros(shape=((%sSize+1),(%sSize+1))) \" %(language, language, language))\n",
    "#     exec(\"%sCount=0\" %(language))\n",
    "#     exec(\"%sEachWordCount=dict.fromkeys(%sAlphabets, 0)\" %(language, language)) #needed for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EN [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n",
      "ES [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n",
      "EU [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n",
      "CA [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n",
      "PT [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n",
      "gl [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]] (53, 53)\n"
     ]
    }
   ],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = dict.fromkeys(a, 0)\n",
    "# print(trainDict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start_time = datetime.now()\n",
    "# delta = 0.5\n",
    "# for language, tweets in trainDict.items():\n",
    "#     for tweet in tweets:\n",
    "#         for i in range(len(tweet)-1):\n",
    "#             first = tweet[i]\n",
    "#             exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary\n",
    "#             exec('%sModel[index] += 1'%(language)) #np.add.at(esModel, [index], 1) #increment that index in the language model\n",
    "# for language in languages:\n",
    "#     exec('%sModel = %sModel/%sModel.sum()'%(language, language, language)) #divide all the values by the sum of the row\n",
    "#     exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "# print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time (hh:mm:ss.ms) 0:00:40.977785\n"
     ]
    }
   ],
   "source": [
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-2):\n",
    "            first = tweet[i]\n",
    "            second = tweet[i+1]\n",
    "            if (not first.isspace()) and (not second.isspace()):\n",
    "                exec('firstIndex = %sAlphabets[first]'%(language))\n",
    "                exec('secondIndex = %sAlphabets[second]'%(language))\n",
    "                exec('%sModel[firstIndex][secondIndex] += 1'%(language))\n",
    "for language in languages:\n",
    "    exec('%sModel = np.add(%sModel, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModel = %sModel/%sModel.sum(axis=1)'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en [[-2.2460059  -1.52720012 -1.30706795 ... -1.86332286 -1.79339122\n",
      "  -1.72427587]\n",
      " [-1.90358322 -2.15044941 -2.70500796 ... -2.34044411 -1.5245459\n",
      "  -1.72427587]\n",
      " [-1.90358322 -2.84941941 -2.00603795 ... -2.34044411 -2.161368\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-2.94497591 -2.84941941 -2.2278867  ... -2.34044411 -2.161368\n",
      "  -1.72427587]\n",
      " [-1.9907334  -2.15044941 -2.70500796 ... -2.34044411 -2.63848926\n",
      "  -1.72427587]\n",
      " [-2.94497591 -2.84941941 -2.70500796 ... -2.34044411 -2.63848926\n",
      "  -1.72427587]]\n",
      "es [[-1.83661251 -2.26502873 -3.50061149 ... -1.53258139 -1.98571698\n",
      "  -1.72427587]\n",
      " [-1.80482068 -1.67995813 -1.23689654 ... -1.92255247 -1.40325255\n",
      "  -1.72427587]\n",
      " [-2.143175   -0.74900754 -2.46987688 ... -2.21061749 -1.85443807\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-2.21572566 -3.71586412 -3.15818881 ... -1.70070372 -2.17477322\n",
      "  -1.72427587]\n",
      " [-2.69284692 -2.61812767 -3.44625383 ... -2.11884711 -1.69765196\n",
      "  -1.72427587]\n",
      " [-3.7342396  -5.03808342 -4.67670275 ... -3.44106641 -3.2161659\n",
      "  -1.72427587]]\n",
      "eu [[-0.95424251 -1.96920079 -2.88138466 ... -1.89762709 -1.79934055\n",
      "  -1.72427587]\n",
      " [-1.99563519 -1.5646302  -0.62370608 ... -1.89762709 -1.79934055\n",
      "  -1.72427587]\n",
      " [-2.47275645 -3.08314414 -2.4042634  ... -1.89762709 -1.32221929\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-1.99563519 -3.08314414 -2.88138466 ... -1.89762709 -1.79934055\n",
      "  -1.72427587]\n",
      " [-2.47275645 -3.08314414 -2.88138466 ... -1.89762709 -1.79934055\n",
      "  -1.72427587]\n",
      " [-2.47275645 -3.08314414 -2.88138466 ... -1.89762709 -1.79934055\n",
      "  -1.72427587]]\n",
      "ca [[-1.99913054 -1.82185741 -3.82157903 ... -1.78532984 -2.31175386\n",
      "  -1.72427587]\n",
      " [-1.99913054 -1.47211182 -0.81941297 ... -1.56348109 -1.61278386\n",
      "  -1.72427587]\n",
      " [-1.99913054 -1.25815443 -1.0788539  ... -2.26245109 -1.61278386\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-2.22097929 -3.96487221 -3.12260902 ... -1.56348109 -1.83463261\n",
      "  -1.72427587]\n",
      " [-1.99913054 -2.68611861 -3.34445777 ... -1.56348109 -1.46665582\n",
      "  -1.72427587]\n",
      " [-2.69810055 -3.96487221 -3.82157903 ... -2.26245109 -2.31175386\n",
      "  -1.72427587]]\n",
      "pt [[-1.6300784  -0.6788734  -1.18737999 ... -1.99563519 -2.39269695\n",
      "  -1.72427587]\n",
      " [-1.15916146 -2.03577904 -0.77575328 ... -1.99563519 -2.39269695\n",
      "  -1.72427587]\n",
      " [-0.94234078 -2.79372691 -1.40563207 ... -1.99563519 -1.69372695\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-3.19303179 -3.83511959 -3.86952506 ... -1.99563519 -1.69372695\n",
      "  -1.72427587]\n",
      " [-3.03333095 -3.83511959 -3.86952506 ... -1.99563519 -0.26236318\n",
      "  -1.72427587]\n",
      " [-4.1472743  -3.83511959 -3.86952506 ... -1.99563519 -2.39269695\n",
      "  -1.72427587]]\n",
      "gl [[-2.29003461 -2.05948768 -2.29885308 ... -2.0374265  -1.36172784\n",
      "  -1.72427587]\n",
      " [-1.81291336 -1.41210471 -1.04139269 ... -1.33845649 -1.83884909\n",
      "  -1.72427587]\n",
      " [-2.29003461 -1.31441289 -1.39085575 ... -1.56030524 -1.83884909\n",
      "  -1.72427587]\n",
      " ...\n",
      " [-2.29003461 -2.61232965 -3.34024576 ... -0.80697758 -1.36172784\n",
      "  -1.72427587]\n",
      " [-2.29003461 -3.45742769 -3.34024576 ... -1.56030524 -1.83884909\n",
      "  -1.72427587]\n",
      " [-2.29003461 -3.45742769 -3.34024576 ... -2.0374265  -1.83884909\n",
      "  -1.72427587]]\n"
     ]
    }
   ],
   "source": [
    "for language in languages:\n",
    "    exec('print(\\'%s\\', %sModel)'%(language, language))\n",
    "#     exec('print(\\'%s\\', %sModelFinal)'%(language, language))\n",
    "\n",
    "# print('EN',enModel, enModel.shape)\n",
    "# print('EN',enModel, enModel.shape)\n",
    "# print('ES',esModel, esModel.shape)\n",
    "# print('ES',esModel, esModel.shape)\n",
    "# print('EU',euModel, euModel.shape)\n",
    "# print('EU',euModel, euModel.shape)\n",
    "# print('CA',caModel, caModel.shape)\n",
    "# print('PT',ptModel, ptModel.shape)\n",
    "# print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glSum = glModel.sum()\n",
    "# ptSum = ptModel.sum()\n",
    "# caSum = caModel.sum()\n",
    "# euSum = euModel.sum()\n",
    "# esSum = esModel.sum()\n",
    "# enSum = enModel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('enSum', enSum ,'\\nesSum', esSum ,'\\neuSum', euSum ,'\\ncaSum', caSum ,'\\nptSum', ptSum, '\\nglSum', glSum)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enModel)\n",
    "row = enModel[0:1]\n",
    "# print('row: ', row)\n",
    "# y = np.zeros(shape=((row.shape)))\n",
    "colum = enModel[0][0]\n",
    "# print('column', colum)\n",
    "\n",
    "x = row\n",
    "y = np.full((row.shape), row[0][0])\n",
    "x = x.flatten()\n",
    "y = y.flatten()\n",
    "# print(x.shape)\n",
    "# print(y.shape)\n",
    "xAxis = enAlphabets.keys()\n",
    "# print(xAxis)\n",
    "\n",
    "# print('x:\\n',x)\n",
    "# print('y:\\n ',y)\n",
    "area = (10 * np.random.rand(x.shape[0]))**2\n",
    "colors = np.random.rand(x.shape[0])\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10\n",
    "x = np.random.rand(N)\n",
    "y = np.random.rand(N)\n",
    "colors = np.random.rand(N)\n",
    "area = (30 * np.random.rand(N))**2  # 0 to 15 point radii\n",
    "print(x.shape)\n",
    "print(y.shape)\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()  # an empty figure with no axes\n",
    "fig.suptitle('First Trial')  # Add a title so we know which it is\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.3)\n",
    "plt.xlabel('x label')\n",
    "plt.ylabel('y label')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TweetID</th>\n",
       "      <th>Language</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>439381946939232257</td>\n",
       "      <td>es</td>\n",
       "      <td>Foto antes de LA FOTO. #orla @ Universidad de ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>439389330533273600</td>\n",
       "      <td>es</td>\n",
       "      <td>@Nagore_Robles Que mal lo vas a pasar viendo a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>439392779786285056</td>\n",
       "      <td>es</td>\n",
       "      <td>Hay cosas complicadas, y luego est치 quitarse l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>439393603845373952</td>\n",
       "      <td>es</td>\n",
       "      <td>Me duele todo, que asco.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>439395306464346112</td>\n",
       "      <td>eu</td>\n",
       "      <td>Ta aste txuriyakin hastekoo bizitzako parriaak...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              TweetID Language  \\\n",
       "0  439381946939232257       es   \n",
       "1  439389330533273600       es   \n",
       "2  439392779786285056       es   \n",
       "3  439393603845373952       es   \n",
       "4  439395306464346112       eu   \n",
       "\n",
       "                                               Tweet  \n",
       "0  Foto antes de LA FOTO. #orla @ Universidad de ...  \n",
       "1  @Nagore_Robles Que mal lo vas a pasar viendo a...  \n",
       "2  Hay cosas complicadas, y luego est치 quitarse l...  \n",
       "3                           Me duele todo, que asco.  \n",
       "4  Ta aste txuriyakin hastekoo bizitzako parriaak...  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/test-tweets-given.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=100)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]\n",
    "_df0 = df[['TweetID', 'Language', 'Tweet']].copy()\n",
    "# pattern = re.compile('[a-z ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "439381946939232257    ca    -4.86E+01    es wrong\n",
      "439389330533273600    es    -8.50E+01    es correct\n",
      "439392779786285056    es    -4.58E+01    es correct\n",
      "439393603845373952    es    -1.39E+01    es correct\n",
      "439395306464346112    eu    -4.16E+01    eu correct\n",
      "439403680245493760    en    -2.05E+01    es wrong\n",
      "439407703358967808    es    -8.57E+01    es correct\n",
      "439408603167211520    es    -6.13E+01    es correct\n",
      "439410377286492160    en    -6.13E+01    es wrong\n",
      "439411327971643392    es    -8.35E+01    es correct\n",
      "439414230413217792    es    -7.46E+01    es correct\n",
      "439415113045778432    eu    -2.22E+01    eu correct\n",
      "439420783698640896    es    -2.24E+01    es correct\n",
      "439428207222484992    es    -1.32E+01    es correct\n",
      "439435803983634432    es    -3.81E+01    es correct\n",
      "439437804352057344    es    -2.21E+01    es correct\n",
      "439438406117232640    es    -4.30E+01    es correct\n",
      "439449097658195968    es    -9.38E+01    es correct\n",
      "439455534304210944    eu    -6.29E+01    eu correct\n",
      "439460634212970496    es    -2.58E+01    es correct\n",
      "439461162816905216    es    -4.38E+01    es correct\n",
      "439461272560877569    es    -3.64E+01    es correct\n",
      "439467342360485888    ca    -2.31E+01    en wrong\n",
      "439473200100282368    es    -1.23E+01    es correct\n",
      "439480968534298625    es    -4.19E+01    es correct\n",
      "439482014878941185    en    -1.80E+01    es wrong\n",
      "439484110122524672    es    -5.42E+01    es correct\n",
      "439484501455302657    pt    -3.09E+01    es wrong\n",
      "439487980601106432    es    -2.30E+01    es correct\n",
      "439498752056123392    es    -6.77E+01    es correct\n",
      "439503131714797570    pt    -2.65E+01    es wrong\n",
      "439504494284800000    eu    -4.42E+01    eu correct\n",
      "439505183505387520    eu    -6.14E+01    es wrong\n",
      "439507371220828160    es    -5.71E+01    es correct\n",
      "439507713610231810    es    -1.46E+01    es correct\n",
      "439513724815421440    gl    -3.37E+01    es wrong\n",
      "439516149727117313    es    -5.70E+01    es correct\n",
      "439516952927952897    es    -2.62E+01    es correct\n",
      "439518973169008640    es    -4.51E+01    es correct\n",
      "439520703696883713    en    -8.94E+00    es wrong\n",
      "439522984446144512    eu    -5.30E+01    es wrong\n",
      "439525439430995968    es    -3.00E+01    es correct\n",
      "439534259318312960    es    -3.12E+01    es correct\n",
      "439535499850813441    ca    -3.17E+01    es wrong\n",
      "439535613822664704    gl    -8.16E+00    es wrong\n",
      "439536938664878080    es    -7.34E+01    es correct\n",
      "439537235042766848    es    -6.77E+01    es correct\n",
      "439537999442112512    es    -2.42E+01    es correct\n",
      "439540887056838656    eu    -4.77E+01    es wrong\n",
      "439541111531790336    es    -4.73E+01    es correct\n",
      "439542604355870720    es    -7.26E+01    es correct\n",
      "439542606624993280    es    -4.27E+01    es correct\n",
      "439555042723766272    es    -5.22E+01    es correct\n",
      "439558368873971712    es    -6.71E+01    es correct\n",
      "439560861586558976    es    -7.58E+01    es correct\n",
      "439567982818525184    es    -3.03E+01    es correct\n",
      "439577257435463680    gl    -4.13E+01    es wrong\n",
      "439608667051405312    gl    -6.52E+01    es wrong\n",
      "439637547665612800    es    -2.28E+01    es correct\n",
      "439645755952070656    es    -7.58E+01    es correct\n",
      "439657427320180736    es    -1.09E+02    es correct\n",
      "439663966571495425    es    -3.71E+01    es correct\n",
      "439670178251829248    es    -6.49E+01    es correct\n",
      "439684933595197440    gl    -2.90E+01    es wrong\n",
      "439687870098726913    es    -2.46E+01    es correct\n",
      "439687998012395520    es    -2.34E+01    es correct\n",
      "439688683978248192    es    -3.95E+01    es correct\n",
      "439692909018099712    eu    -1.05E+01    eu correct\n",
      "439696075122028544    es    -7.27E+01    es correct\n",
      "439697970804834304    es    -2.71E+01    es correct\n",
      "439701625616474112    pt    -1.33E+01    es wrong\n",
      "439706164432224256    eu    -3.37E+01    eu correct\n",
      "439709342955474944    es    -3.34E+01    es correct\n",
      "439713198129025024    es    -1.12E+01    es correct\n",
      "439714893332508672    es    -2.27E+01    eu wrong\n",
      "439718759201509376    es    -1.48E+01    es correct\n",
      "439719845756940288    es    -3.51E+01    es correct\n",
      "439722026287529984    es    -1.60E+01    es correct\n",
      "439723376354287616    es    -9.51E+01    es correct\n",
      "439723585494859777    gl    -3.59E+01    es wrong\n",
      "439723745511743488    es    -2.29E+01    es correct\n",
      "439725940768538624    es    -1.08E+01    es correct\n",
      "439726309103898624    es    -6.94E+01    es correct\n",
      "439728314744586240    es    -3.90E+01    es correct\n",
      "439733759790030848    ca    -3.17E+01    es wrong\n",
      "439734193401397248    eu    -1.43E+01    en wrong\n",
      "439735656383012864    gl    -1.97E+01    es wrong\n",
      "439739248175226881    es    -1.43E+01    es correct\n",
      "439741213668020224    eu    -7.92E+01    es wrong\n",
      "439742711311380480    es    -1.74E+01    es correct\n",
      "439743216196521985    es    -3.44E+01    es correct\n",
      "439744756328169472    ca    -3.03E+01    es wrong\n",
      "439745131479322625    es    -1.63E+01    es correct\n",
      "439745133052186625    gl    -5.31E+01    es wrong\n",
      "439748495395020800    es    -7.11E+01    es correct\n",
      "439751898217070592    es    -5.81E+01    es correct\n",
      "439753018041708546    es    -1.05E+02    es correct\n",
      "439755659622776832    en    -1.52E+01    es wrong\n",
      "439756762099351552    gl    -1.15E+01    es wrong\n",
      "439758392232792064    es    -1.98E+01    es correct\n"
     ]
    }
   ],
   "source": [
    "probability = {}\n",
    "for index, row in _df0.iterrows():\n",
    "    for language in languages:\n",
    "        exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "    tweetID = row['TweetID']\n",
    "    langTweet = row['Language']\n",
    "    tweet = row['Tweet']\n",
    "    \n",
    "    for i in range(len(tweet)-2):\n",
    "        first = tweet[i]\n",
    "        second = tweet[i+1]\n",
    "        for language in languages:\n",
    "            exec('if ( (not pattern.match(first)) or (not pattern.match(second)) ):\\n\\\n",
    "    prob = 0\\n\\\n",
    "elif ( (first not in {lang}Alphabets.keys()) and (second not in {lang}Alphabets.keys()) ):\\n\\\n",
    "    prob = {lang}Model[-1][-1]\\n\\\n",
    "elif (second not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[first]\\n\\\n",
    "    prob = {lang}Model[index][-1]\\n\\\n",
    "elif (first not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {lang}Alphabets[first]\\n\\\n",
    "    secondIndex = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[firstIndex][secondIndex]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang=language))\n",
    "    for langu in languages:\n",
    "        exec(\"probability['%s'] = %sProb\"%(langu, langu))\n",
    "    result = max(probability, key=probability.get)\n",
    "    print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', langTweet, 'correct' if (langTweet==result) else 'wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if vocab=='2':\n",
      "    if (not first.islapha()) and (not second.isalpha()):\n",
      "        prob = 0\n",
      "else:\n",
      "    if ( (not pattern.match(first)) or (not pattern.match(second)) ):\n",
      "        prob = 0\n",
      "if ( (first not in enAlphabets.keys()) and (second not in enAlphabets.keys()) ):\n",
      "    prob = enModel[-1][-1]\n",
      "elif (second not in enAlphabets.keys()):\n",
      "    index = enAlphabets[first]\n",
      "    prob = enModel[index][-1]\n",
      "elif (first not in enAlphabets.keys()):\n",
      "    index = enAlphabets[second]\n",
      "    prob = enModel[-1][index]\n",
      "else:\n",
      "    firstIndex = enAlphabets[first]\n",
      "    secondIndex = enAlphabets[second]\n",
      "    prob = enModel[firstIndex][secondIndex]\n",
      "enProb = prob + enProb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "str = 'if vocab==\\'2\\':\\n\\\n",
    "    if (not first.islapha()) and (not second.isalpha()):\\n\\\n",
    "        prob = 0\\n\\\n",
    "else:\\n\\\n",
    "    if ( (not pattern.match(first)) or (not pattern.match(second)) ):\\n\\\n",
    "        prob = 0\\n\\\n",
    "if ( (first not in {lang}Alphabets.keys()) and (second not in {lang}Alphabets.keys()) ):\\n\\\n",
    "    prob = {lang}Model[-1][-1]\\n\\\n",
    "elif (second not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[first]\\n\\\n",
    "    prob = {lang}Model[index][-1]\\n\\\n",
    "elif (first not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {lang}Alphabets[first]\\n\\\n",
    "    secondIndex = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[firstIndex][secondIndex]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang='en')#, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang, lang)\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(64.0).reshape((4,4,4))\n",
    "print('before',a)\n",
    "for x in range(a.shape[0]):\n",
    "    for y in range(a.shape[1]):\n",
    "        sumCol = a[x,y,:]\n",
    "        sumCol = np.add(sumCol, 1)\n",
    "        sumCol = np.divide(sumCol, sumCol.sum(axis=0))\n",
    "        sumCol = np.log10(sumCol)\n",
    "        a[x,y,:] = sumCol\n",
    "print('after:', a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(27.0).reshape((3,3,3))\n",
    "print('before',a)\n",
    "X = a[0,0,:]\n",
    "X = np.add(X, 1)\n",
    "X = np.divide(X, X.sum(axis=0))\n",
    "a[0,0,:] = X\n",
    "print('after',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9.0).reshape((3,3))\n",
    "print('before',a)\n",
    "X = a[0,:]\n",
    "X = np.add(X, 1)\n",
    "X = np.divide(X, X.sum(axis=0))\n",
    "a[0,:] = X\n",
    "print('after',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(3.0).reshape((3))\n",
    "print('before',a)\n",
    "X = a[:]\n",
    "X = np.add(X, 1)\n",
    "X = np.divide(X, X.sum(axis=0))\n",
    "a[:] = X\n",
    "print('after',a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "if self.vocab=='2':\n",
      "    if (not first.isalpha()) and (not second.isalpha()):\n",
      "        prob = 0\n",
      "else:\n",
      "    if ( (not self.pattern.match(first)) or (not self.pattern.match(second)) ):\n",
      "        prob = 0\n",
      "if ( (first not in enAlphabets.keys()) and (second not in enAlphabets.keys()) ):\n",
      "    prob = enModel[-1][-1]\n",
      "elif (second not in enAlphabets.keys()):\n",
      "    index = enAlphabets[first]\n",
      "    prob = enModel[index][-1]\n",
      "elif (first not in enAlphabets.keys()):\n",
      "    index = enAlphabets[second]\n",
      "    prob = enModel[-1][index]\n",
      "else:\n",
      "    firstIndex = enAlphabets[first]\n",
      "    secondIndex = enAlphabets[second]\n",
      "    prob = enModel[firstIndex][secondIndex]\n",
      "enProb = prob + enProb\n",
      "\n"
     ]
    }
   ],
   "source": [
    "str = 'if self.vocab==\\'2\\':\\n\\\n",
    "    if (not first.isalpha()) and (not second.isalpha()):\\n\\\n",
    "        prob = 0\\n\\\n",
    "else:\\n\\\n",
    "    if ( (not self.pattern.match(first)) or (not self.pattern.match(second)) ):\\n\\\n",
    "        prob = 0\\n\\\n",
    "if ( (first not in {lang}Alphabets.keys()) and (second not in {lang}Alphabets.keys()) ):\\n\\\n",
    "    prob = {lang}Model[-1][-1]\\n\\\n",
    "elif (second not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[first]\\n\\\n",
    "    prob = {lang}Model[index][-1]\\n\\\n",
    "elif (first not in {lang}Alphabets.keys()):\\n\\\n",
    "    index = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[-1][index]\\n\\\n",
    "else:\\n\\\n",
    "    firstIndex = {lang}Alphabets[first]\\n\\\n",
    "    secondIndex = {lang}Alphabets[second]\\n\\\n",
    "    prob = {lang}Model[firstIndex][secondIndex]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang='en')\n",
    "print(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
