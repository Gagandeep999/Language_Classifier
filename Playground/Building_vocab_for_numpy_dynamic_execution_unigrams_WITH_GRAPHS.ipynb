{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "from decimal import Decimal\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)\n",
    "print('matplotlib: ',matplotlib.__version__)\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=10000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[ ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if letter.isalpha() or pattern.match(letter):\n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(enSize)\n",
    "print(enAlphabets)\n",
    "print(esSize)\n",
    "print(esAlphabets)\n",
    "print(euSize)\n",
    "print(euAlphabets)\n",
    "print(caSize)\n",
    "print(caAlphabets)\n",
    "print(ptSize)\n",
    "print(ptAlphabets)\n",
    "print(glSize)\n",
    "print(glAlphabets)\n",
    "print(trainDict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(shape=(%sSize+1))\" %(language, language))\n",
    "#     exec(\"%sCount=0\" %(language))\n",
    "#     exec(\"%sEachWordCount=dict.fromkeys(%sAlphabets, 0)\" %(language, language)) #needed for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = dict.fromkeys(a, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-1):\n",
    "            first = tweet[i]\n",
    "            exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary\n",
    "#             exec('np.add.at(%sModel, [index], 1)'%(language)) #np.add.at(esModel, [index], 1) #increment that index in the language model\n",
    "            exec('%sModel[index] += 1'%(language))\n",
    "for language in languages:\n",
    "    exec('%sModel = np.add(%sModel, delta)'%(language, language)) #this is where smoothing happens\n",
    "    exec('%sModel = %sModel/%sModel.sum()'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glSum = glModel.sum()\n",
    "# ptSum = ptModel.sum()\n",
    "# caSum = caModel.sum()\n",
    "# euSum = euModel.sum()\n",
    "# esSum = esModel.sum()\n",
    "# enSum = enModel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('enSum', enSum ,'\\nesSum', esSum ,'\\neuSum', euSum ,'\\ncaSum', caSum ,'\\nptSum', ptSum, '\\nglSum', glSum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enAlphabets.values())\n",
    "# print(enModel)\n",
    "# print(type(list(enAlphabets.values())))\n",
    "# npa = np.asarray(someListOfLists, dtype=np.float32)\n",
    "x = np.asarray(list(enAlphabets.values()))\n",
    "x = np.append(x, (x.shape[0]))\n",
    "y = enModel\n",
    "print('x:\\n', x)\n",
    "print('y:\\n', y)\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.set_size_inches(15, 3)\n",
    "area = (10 * np.random.rand(x.shape[0]))**2\n",
    "colors = np.random.rand(x.shape[0])\n",
    "plt.title('SUQ MADIQ')\n",
    "plt.xlabel('Alphabets')\n",
    "plt.ylabel('Probability of alphabet')\n",
    "plt.scatter(x, y, s=area, c=colors, alpha=0.7)\n",
    "plt.xticks(x, list(enAlphabets.keys()))\n",
    "plt.tick_params(axis='x', which='minor', labelsize=10, width = 5)\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/test-tweets-given.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=100)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]\n",
    "_df0 = df[['TweetID', 'Language', 'Tweet']].copy()\n",
    "# pattern = re.compile('[a-z ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probability = {}\n",
    "for index, row in _df0.iterrows():\n",
    "    for language in languages:\n",
    "        exec(\"%sProb=math.log10(1/6)\" % (language))\n",
    "    tweetID = row['TweetID']\n",
    "    langTweet = row['Language']\n",
    "    tweet = row['Tweet']\n",
    "    \n",
    "    for i in range(len(tweet)-2):\n",
    "        first = tweet[i]\n",
    "        for lang in languages:\n",
    "            exec('if (first not in {0}Alphabets.keys()):\\n\\\n",
    "    prob = {1}Model[-1]\\n\\\n",
    "else:\\n\\\n",
    "    index = {2}Alphabets[first]\\n\\\n",
    "    prob = {3}Model[index]\\n\\\n",
    "{4}Prob = prob + {5}Prob\\n'.format(lang, lang, lang, lang, lang, lang)) #, lang, lang, lang, lang, lang, lang, lang, lang, lang))\n",
    "    for langu in languages:\n",
    "        exec(\"probability['%s'] = %sProb\"%(langu, langu))\n",
    "#     probability[lang] = enProb\n",
    "#     print(probability)\n",
    "#     print('tweet: ', tweet,'\\nenProb:', enProb, '\\neuProb:', euProb, '\\nesProb:', esProb, '\\ncaProb:', caProb\n",
    "#     ,'\\nptProb:', ptProb, '\\nglProb:', glProb)\n",
    "    result = max(probability, key=probability.get)\n",
    "    print(tweetID, '  ', result, '  ', '%.2E' % Decimal(probability[result]), '  ', langTweet, 'correct' if (langTweet==result) else 'wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'if not self.pattern.match(first):\\n\\\n",
    "    prob = 0\\n\\\n",
    "elif (first not in self.{lang}Alphabets.keys()):\\n\\\n",
    "    prob = self.{lang}Model[-1]\\n\\\n",
    "else:\\n\\\n",
    "    index = self.{lang}Alphabets[first]\\n\\\n",
    "    prob = self.{lang}Model[index]\\n\\\n",
    "{lang}Prob = prob + {lang}Prob\\n'.format(lang='en')\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
