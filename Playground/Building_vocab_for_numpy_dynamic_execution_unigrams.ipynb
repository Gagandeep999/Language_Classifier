{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import math\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime \n",
    "import numpy as np\n",
    "print('numpy: ',np.version.version)\n",
    "print('pandas: ',pd.__version__)\n",
    "languages = ['en', 'es', 'eu', 'ca', 'pt', 'gl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../OriginalDataSet/training-tweets.txt', encoding='utf-8', error_bad_lines=False, sep='\\t', nrows=10000)\n",
    "df.columns = ['TweetID', 'UserID', 'Language', \"Tweet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_df0 = df[['Language', 'Tweet']].copy()\n",
    "pattern = re.compile('[ ]')\n",
    "_df0.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sAlphabets={}\" % (language))\n",
    "    exec ('{0}Size = 0'.format(language))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now() \n",
    "trainDict = defaultdict(list)\n",
    "for index, row in _df0.iterrows():\n",
    "    sentence = ''\n",
    "    tweet = row['Tweet']\n",
    "    language = row['Language']\n",
    "    for letter in tweet:\n",
    "        if letter.isalpha() or pattern.match(letter):\n",
    "            exec('if \\'{0}\\' not in {1}Alphabets.keys():\\n\\\n",
    "                     {2}Alphabets[letter] = {3}Size\\n\\\n",
    "                     {4}Size += 1'.format(letter, language, language, language, language))\n",
    "            sentence = sentence + letter\n",
    "    trainDict[row['Language']].append(sentence)\n",
    "print('Reading time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(enSize)\n",
    "# print(enAlphabets)\n",
    "# print(esSize)\n",
    "# print(esAlphabets)\n",
    "# print(euSize)\n",
    "# print(euAlphabets)\n",
    "# print(caSize)\n",
    "# print(caAlphabets)\n",
    "# print(ptSize)\n",
    "# print(ptAlphabets)\n",
    "# print(glSize)\n",
    "# print(glAlphabets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for language in languages:\n",
    "    exec(\"%sModel=np.zeros(%sSize+1)\" %(language, language))\n",
    "#     exec(\"%sCount=0\" %(language))\n",
    "#     exec(\"%sEachWordCount=dict.fromkeys(%sAlphabets, 0)\" %(language, language)) #needed for bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('EN',enModel, enModel.shape)\n",
    "# print('ES',esModel, esModel.shape)\n",
    "# print('EU',euModel, euModel.shape)\n",
    "# print('CA',caModel, caModel.shape)\n",
    "# print('PT',ptModel, ptModel.shape)\n",
    "# print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = dict.fromkeys(a, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For Unigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = datetime.now()\n",
    "delta = 0.5\n",
    "for language, tweets in trainDict.items():\n",
    "    for tweet in tweets:\n",
    "        for i in range(len(tweet)-1):\n",
    "            first = tweet[i]\n",
    "            exec('index = %sAlphabets[first]'%(language)) #index = esAlphabets[first] #get index of the character from the language dictionary\n",
    "            exec('np.add.at(%sModel, [index], 1)'%(language)) #np.add.at(esModel, [index], 1) #increment that index in the language model\n",
    "for language in languages:\n",
    "    exec('%sModel = %sModel/%sModel.sum()'%(language, language, language)) #divide all the values by the sum of the row\n",
    "    exec('%sModel = np.log10(%sModel)'%(language, language))\n",
    "print('Training time (hh:mm:ss.ms) {}'.format(datetime.now() - start_time ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('EN',enModel, enModel.shape)\n",
    "print('ES',esModel, esModel.shape)\n",
    "print('EU',euModel, euModel.shape)\n",
    "print('CA',caModel, caModel.shape)\n",
    "print('PT',ptModel, ptModel.shape)\n",
    "print('gl',glModel, glModel.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# glSum = glModel.sum()\n",
    "# ptSum = ptModel.sum()\n",
    "# caSum = caModel.sum()\n",
    "# euSum = euModel.sum()\n",
    "# esSum = esModel.sum()\n",
    "# enSum = enModel.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('enSum', enSum ,'\\nesSum', esSum ,'\\neuSum', euSum ,'\\ncaSum', caSum ,'\\nptSum', ptSum, '\\nglSum', glSum)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
